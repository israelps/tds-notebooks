{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-episode",
   "metadata": {},
   "source": [
    "#### 1. Create a Local Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"kmeans-seed-dataset\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-handy",
   "metadata": {},
   "source": [
    "#### 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for ML pipeline and training\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-idaho",
   "metadata": {},
   "source": [
    "#### 3. Import Seeds dataset from a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "common-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset from csv file\n",
    "dataset = spark.read.csv(\"seeds_dataset.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sweet-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(A=15.26, P=14.84, C=0.871, LK=5.763, WK=3.312, A_Coef=2.221, LKG=5.22, target=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-vintage",
   "metadata": {},
   "source": [
    "#### 4. Create a Data pre-processing Pipeline \n",
    "#####   4.1. Create a vector from all features columns\n",
    "#####   4.2. Standardize data\n",
    "#####   4.3. Pass this data to a KMeans object and create the Pipeline object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "advance-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols = dataset.columns[:-1], outputCol='features')\n",
    "\n",
    "scaler = StandardScaler(inputCol=vec_assembler.getOutputCol(), outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "\n",
    "kmeans = KMeans(featuresCol=scaler.getOutputCol()).setK(2).setSeed(1)\n",
    "\n",
    "pipeline = Pipeline(stages=[vec_assembler,scaler,kmeans])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-police",
   "metadata": {},
   "source": [
    "#### 5. Fit and Evaluate the model\n",
    "\n",
    "##### The ClusteringEvaluator use the Silhoute metric do evaluate the model\n",
    "  \n",
    "Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].\n",
    "\n",
    "Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "medium-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.7098457795960431\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(dataset)\n",
    "predictions = model.transform(dataset)\n",
    "\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-bahamas",
   "metadata": {},
   "source": [
    "##### 6. Get the cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "binary-income",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[ 6.2407035  12.29350122 37.40324608 13.82968554  9.69123508  2.31478858\n",
      " 12.15051313]\n",
      "[ 4.44396468 10.48536862 36.54671035 12.05177027  8.0111241   2.5455929\n",
      " 10.33965102]\n"
     ]
    }
   ],
   "source": [
    "centers = model.stages[2].clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-transport",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
